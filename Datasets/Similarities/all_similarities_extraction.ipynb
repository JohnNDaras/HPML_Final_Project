{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mOR9635OL3U",
        "outputId": "c8acc674-90ed-413c-8dc7-23e5b4b0b213"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8I9NqYPOYg-",
        "outputId": "e254b0df-2582-4a3c-aad5-d48f49dd0daf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting shapely\n",
            "  Downloading shapely-2.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.14 in /usr/local/lib/python3.10/dist-packages (from shapely) (1.26.4)\n",
            "Downloading shapely-2.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/2.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/2.5 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: shapely\n",
            "Successfully installed shapely-2.0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install shapely"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1x1x7tGwJdc"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import sys\n",
        "from shapely import wkt\n",
        "from shapely.geometry import GeometryCollection, Polygon, MultiPolygon\n",
        "from collections import deque\n",
        "\n",
        "# Setting the CSV field size limit\n",
        "maxInt = sys.maxsize\n",
        "while True:\n",
        "    try:\n",
        "        csv.field_size_limit(maxInt)\n",
        "        break\n",
        "    except OverflowError:\n",
        "        maxInt = int(maxInt / 10)\n",
        "\n",
        "class CsvReader:\n",
        "    @staticmethod\n",
        "    def readAllEntities(delimiter, inputFilePath, batch_size=1000):\n",
        "        loadedEntities = []\n",
        "        geoCollections = 0\n",
        "        batch = []\n",
        "\n",
        "        def process_batch(batch):\n",
        "            local_entities = []\n",
        "            local_geo_collections = 0\n",
        "\n",
        "            for row in batch:\n",
        "                found_geometry = False\n",
        "                for column in row:\n",
        "                    try:\n",
        "                        geometry = wkt.loads(column)\n",
        "                        found_geometry = True\n",
        "                        break\n",
        "                    except Exception:\n",
        "                        continue\n",
        "                if not found_geometry:\n",
        "                    continue\n",
        "\n",
        "                if isinstance(geometry, GeometryCollection):\n",
        "                    local_geo_collections += 1\n",
        "                else:\n",
        "                    local_entities.append(geometry)\n",
        "\n",
        "            return local_entities, local_geo_collections\n",
        "\n",
        "        # Open and read the CSV file\n",
        "        with open(inputFilePath, newline='') as f:\n",
        "            reader = csv.reader(f, delimiter=delimiter)\n",
        "            for row in reader:\n",
        "                batch.append(row)\n",
        "                if len(batch) >= batch_size:\n",
        "                    entities, geo_collections = process_batch(batch)\n",
        "                    loadedEntities.extend(entities)\n",
        "                    geoCollections += geo_collections\n",
        "                    batch = []\n",
        "\n",
        "            # Process the remaining rows in the last batch\n",
        "            if batch:\n",
        "                entities, geo_collections = process_batch(batch)\n",
        "                loadedEntities.extend(entities)\n",
        "                geoCollections += geo_collections\n",
        "\n",
        "        print(f\"Total entities: {len(loadedEntities)}, Geometry collections: {geoCollections}\")\n",
        "        return loadedEntities\n",
        "\n",
        "    @staticmethod\n",
        "    def loadClusterDataToDeque(inputFilePath):\n",
        "        \"\"\"\n",
        "        Loads cluster data from a CSV file into a deque.\n",
        "        Assumes the CSV file contains two columns: cluster ID (int) and similarity index (float),\n",
        "        and skips the header row.\n",
        "        \"\"\"\n",
        "        cluster_data = deque()\n",
        "        with open(inputFilePath, 'r') as csv_file:\n",
        "            reader = csv.reader(csv_file)\n",
        "            next(reader, None)  # Skip the header row\n",
        "            for row in reader:\n",
        "                cluster_id, similarity_index = int(row[0]), float(row[1])\n",
        "                cluster_data.append((cluster_id, similarity_index))\n",
        "        return cluster_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCqw45mdACPv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from shapely.geometry import Polygon\n",
        "from shapely.affinity import translate\n",
        "from shapely.set_operations import intersection_all, union_all\n",
        "from shapely.strtree import STRtree\n",
        "\n",
        "class ShapeSimilarity:\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    # Function to center polygons at the origin\n",
        "    def center_polygons(self, polygons):\n",
        "        centered_polygons = []\n",
        "        for polygon in polygons:\n",
        "            centroid = polygon.centroid\n",
        "            centered_polygon = translate(polygon, xoff=-centroid.x, yoff=-centroid.y)\n",
        "            centered_polygons.append(centered_polygon)\n",
        "        return np.array(centered_polygons)\n",
        "\n",
        "    # Precompute polygon properties and store them for efficiency\n",
        "    def _precompute_properties(self, polygons):\n",
        "        self.polygons = self.center_polygons(polygons)  # Center all polygons before computing properties\n",
        "        self.num_polygons = len(self.polygons)\n",
        "\n",
        "        # Precompute properties\n",
        "        self.areas = np.array([polygon.area for polygon in self.polygons])\n",
        "        self.perimeters = np.array([polygon.length for polygon in self.polygons])\n",
        "        self.bboxes = np.array([polygon.bounds for polygon in self.polygons])\n",
        "        self.fourier_descriptors = np.array([self._fourier_descriptor(polygon) for polygon in self.polygons])\n",
        "\n",
        "    # Fourier Descriptor for a polygon\n",
        "    def _fourier_descriptor(self, polygon, num_points=128):\n",
        "        coords = np.array(polygon.exterior.coords)\n",
        "        t = np.linspace(0, 1, len(coords))\n",
        "        resampled_t = np.linspace(0, 1, num_points)\n",
        "        resampled_coords = np.column_stack((\n",
        "            np.interp(resampled_t, t, coords[:, 0]),\n",
        "            np.interp(resampled_t, t, coords[:, 1])\n",
        "        ))\n",
        "        complex_coords = resampled_coords[:, 0] + 1j * resampled_coords[:, 1]\n",
        "        fourier_transform = np.fft.fft(complex_coords)\n",
        "        return np.abs(fourier_transform / np.abs(fourier_transform[1]))  # Normalize\n",
        "\n",
        "    # Jaccard Similarity\n",
        "    def jaccard_similarity(self, A, B):\n",
        "        intersection_area = A.intersection(B).area\n",
        "        union_area = A.union(B).area\n",
        "        return intersection_area / union_area if union_area != 0 else 0\n",
        "\n",
        "    # Area Similarity\n",
        "    def area_similarity(self, idx_A, idx_B):\n",
        "        intersection_area = self.polygons[idx_A].intersection(self.polygons[idx_B]).area\n",
        "        return (2 * intersection_area) / (self.areas[idx_A] + self.areas[idx_B]) if self.areas[idx_A] + self.areas[idx_B] > 0 else 0\n",
        "\n",
        "    # Curvature Similarity\n",
        "    def curvature_similarity(self, idx_A, idx_B):\n",
        "        num_vertices_A = len(self.polygons[idx_A].exterior.coords)\n",
        "        num_vertices_B = len(self.polygons[idx_B].exterior.coords)\n",
        "        return np.exp(-abs(num_vertices_A - num_vertices_B) / max(num_vertices_A, num_vertices_B))\n",
        "\n",
        "    # Fourier Descriptor Similarity\n",
        "    def fourier_descriptor_similarity(self, idx_A, idx_B):\n",
        "        return 1 / (1 + np.linalg.norm(self.fourier_descriptors[idx_A] - self.fourier_descriptors[idx_B]))\n",
        "\n",
        "    # Aspect Ratio Similarity\n",
        "    def aspect_ratio_similarity(self, bbox_A, bbox_B):\n",
        "        aspect_ratio_A = (bbox_A[2] - bbox_A[0]) / (bbox_A[3] - bbox_A[1]) if bbox_A[3] != bbox_A[1] else 0\n",
        "        aspect_ratio_B = (bbox_B[2] - bbox_B[0]) / (bbox_B[3] - bbox_B[1]) if bbox_B[3] != bbox_B[1] else 0\n",
        "        return 1 / (1 + abs(aspect_ratio_A - aspect_ratio_B))\n",
        "\n",
        "    # Perimeter Similarity\n",
        "    def perimeter_similarity(self, idx_A, idx_B):\n",
        "        return 1 / (1 + abs(self.perimeters[idx_A] - self.perimeters[idx_B]))\n",
        "\n",
        "    # Bounding Box Distance\n",
        "    def bounding_box_distance(self, idx_A, idx_B):\n",
        "        center_A = ((self.bboxes[idx_A][0] + self.bboxes[idx_A][2]) / 2, (self.bboxes[idx_A][1] + self.bboxes[idx_A][3]) / 2)\n",
        "        center_B = ((self.bboxes[idx_B][0] + self.bboxes[idx_B][2]) / 2, (self.bboxes[idx_B][1] + self.bboxes[idx_B][3]) / 2)\n",
        "        dist_centers = np.linalg.norm(np.array(center_A) - np.array(center_B))\n",
        "        return 1 / (1 + dist_centers)\n",
        "\n",
        "    # Polygon Circularity Similarity\n",
        "    def polygon_circularity_similarity(self, idx_A, idx_B):\n",
        "        circularity_A = (4 * np.pi * self.areas[idx_A]) / (self.perimeters[idx_A] ** 2) if self.perimeters[idx_A] != 0 else 0\n",
        "        circularity_B = (4 * np.pi * self.areas[idx_B]) / (self.perimeters[idx_B] ** 2) if self.perimeters[idx_B] != 0 else 0\n",
        "        return 1 / (1 + abs(circularity_A - circularity_B))\n",
        "\n",
        "    # Combined similarity calculation for each unique pair\n",
        "    def combined_similarity(self, idx_A, idx_B, w_jaccard=0.125, w_area=0.125, w_curvature=0.125, w_fourier=0.125,\n",
        "                            w_aspect_ratio=0.125, w_perimeter=0.125, w_bbox=0.125, w_circularity=0.125):\n",
        "\n",
        "        jaccard_sim = self.jaccard_similarity(self.polygons[idx_A], self.polygons[idx_B])\n",
        "        area_sim = self.area_similarity(idx_A, idx_B)\n",
        "        curvature_sim = self.curvature_similarity(idx_A, idx_B)\n",
        "        fourier_sim = self.fourier_descriptor_similarity(idx_A, idx_B)\n",
        "        aspect_ratio_sim = self.aspect_ratio_similarity(self.bboxes[idx_A], self.bboxes[idx_B])\n",
        "        perimeter_sim = self.perimeter_similarity(idx_A, idx_B)\n",
        "        bbox_dist = self.bounding_box_distance(idx_A, idx_B)\n",
        "        circularity_sim = self.polygon_circularity_similarity(idx_A, idx_B)\n",
        "\n",
        "        return (w_jaccard * jaccard_sim +\n",
        "                w_area * area_sim +\n",
        "                w_curvature * curvature_sim +\n",
        "                w_fourier * fourier_sim +\n",
        "                w_aspect_ratio * aspect_ratio_sim +\n",
        "                w_perimeter * perimeter_sim +\n",
        "                w_bbox * bbox_dist +\n",
        "                w_circularity * circularity_sim) * 100\n",
        "\n",
        "    # Calculate average similarity for all unique pairs\n",
        "    def calculate_similarity_all_pairs(self, polygons_array):\n",
        "        self._precompute_properties(polygons_array)\n",
        "        similarity_scores = []\n",
        "\n",
        "        for i in range(self.num_polygons):\n",
        "            for j in range(i + 1, self.num_polygons):\n",
        "                similarity_score = self.combined_similarity(i, j)\n",
        "                similarity_scores.append(similarity_score)\n",
        "\n",
        "        return np.mean(similarity_scores) if similarity_scores else 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3scNbR373x4J"
      },
      "outputs": [],
      "source": [
        "from shapely import relate\n",
        "from shapely import Point, LineString, Polygon, MultiPoint, MultiLineString, MultiPolygon\n",
        "from shapely import get_num_coordinates\n",
        "\n",
        "class RelatedGeometries:\n",
        "    def __init__(self):\n",
        "        self.verifiedClusters = 0\n",
        "\n",
        "        # Lists to store counts of geometries by similarity ranges (0-100%)\n",
        "        self.similarity_0_10 = []\n",
        "        self.similarity_10_20 = []\n",
        "        self.similarity_20_30 = []\n",
        "        self.similarity_30_40 = []\n",
        "        self.similarity_40_50 = []\n",
        "        self.similarity_50_60 = []\n",
        "        self.similarity_60_70 = []\n",
        "        self.similarity_70_80 = []\n",
        "        self.similarity_80_90 = []\n",
        "        self.similarity_90_100 = []\n",
        "\n",
        "    # Methods to add geometries to the corresponding similarity range\n",
        "    def addSimilarity(self, cluster, similarity):\n",
        "        if 0 <= similarity < 10:\n",
        "            self.similarity_0_10.append(cluster)\n",
        "        elif 10 <= similarity < 20:\n",
        "            self.similarity_10_20.append(cluster)\n",
        "        elif 20 <= similarity < 30:\n",
        "            self.similarity_20_30.append(cluster)\n",
        "        elif 30 <= similarity < 40:\n",
        "            self.similarity_30_40.append(cluster)\n",
        "        elif 40 <= similarity < 50:\n",
        "            self.similarity_40_50.append(cluster)\n",
        "        elif 50 <= similarity < 60:\n",
        "            self.similarity_50_60.append(cluster)\n",
        "        elif 60 <= similarity < 70:\n",
        "            self.similarity_60_70.append(cluster)\n",
        "        elif 70 <= similarity < 80:\n",
        "            self.similarity_70_80.append(cluster)\n",
        "        elif 80 <= similarity < 90:\n",
        "            self.similarity_80_90.append(cluster)\n",
        "        elif 90 <= similarity <= 100:\n",
        "            self.similarity_90_100.append(cluster)\n",
        "\n",
        "    # Get counts of Clusters in each similarity range\n",
        "    def getNoOfClustersInRange(self, lower_bound, upper_bound):\n",
        "        if lower_bound == 0 and upper_bound == 10:\n",
        "            return len(self.similarity_0_10)\n",
        "        elif lower_bound == 10 and upper_bound == 20:\n",
        "            return len(self.similarity_10_20)\n",
        "        elif lower_bound == 20 and upper_bound == 30:\n",
        "            return len(self.similarity_20_30)\n",
        "        elif lower_bound == 30 and upper_bound == 40:\n",
        "            return len(self.similarity_30_40)\n",
        "        elif lower_bound == 40 and upper_bound == 50:\n",
        "            return len(self.similarity_40_50)\n",
        "        elif lower_bound == 50 and upper_bound == 60:\n",
        "            return len(self.similarity_50_60)\n",
        "        elif lower_bound == 60 and upper_bound == 70:\n",
        "            return len(self.similarity_60_70)\n",
        "        elif lower_bound == 70 and upper_bound == 80:\n",
        "            return len(self.similarity_70_80)\n",
        "        elif lower_bound == 80 and upper_bound == 90:\n",
        "            return len(self.similarity_80_90)\n",
        "        elif lower_bound == 90 and upper_bound == 100:\n",
        "            return len(self.similarity_90_100)\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def reset(self):\n",
        "        self.verifiedClusters = 0\n",
        "\n",
        "        # Clear similarity ranges\n",
        "        self.similarity_0_10.clear()\n",
        "        self.similarity_10_20.clear()\n",
        "        self.similarity_20_30.clear()\n",
        "        self.similarity_30_40.clear()\n",
        "        self.similarity_40_50.clear()\n",
        "        self.similarity_50_60.clear()\n",
        "        self.similarity_60_70.clear()\n",
        "        self.similarity_70_80.clear()\n",
        "        self.similarity_80_90.clear()\n",
        "        self.similarity_90_100.clear()\n",
        "\n",
        "    def print(self):\n",
        "        print(\"Clusters in 0-10% similarity range:\\t\", str(len(self.similarity_0_10)))\n",
        "        print(\"Clusters in 10-20% similarity range:\\t\", str(len(self.similarity_10_20)))\n",
        "        print(\"Clusters in 20-30% similarity range:\\t\", str(len(self.similarity_20_30)))\n",
        "        print(\"Clusters in 30-40% similarity range:\\t\", str(len(self.similarity_30_40)))\n",
        "        print(\"Clusters in 40-50% similarity range:\\t\", str(len(self.similarity_40_50)))\n",
        "        print(\"Clusters in 50-60% similarity range:\\t\", str(len(self.similarity_50_60)))\n",
        "        print(\"Clusters in 60-70% similarity range:\\t\", str(len(self.similarity_60_70)))\n",
        "        print(\"Clusters in 70-80% similarity range:\\t\", str(len(self.similarity_70_80)))\n",
        "        print(\"Clusters in 80-90% similarity range:\\t\", str(len(self.similarity_80_90)))\n",
        "        print(\"Clusters in 90-100% similarity range:\\t\", str(len(self.similarity_90_100)))\n",
        "        print(\"Verified Clusters\", str(self.verifiedClusters))\n",
        "\n",
        "    def verifyRelations(self, cluster, similarity):\n",
        "        self.verifiedClusters += 1\n",
        "\n",
        "        # Add the cluster to the corresponding similarity range\n",
        "        if 0 <= similarity < 10:\n",
        "            self.similarity_0_10.append(cluster)\n",
        "        elif 10 <= similarity < 20:\n",
        "            self.similarity_10_20.append(cluster)\n",
        "        elif 20 <= similarity < 30:\n",
        "            self.similarity_20_30.append(cluster)\n",
        "        elif 30 <= similarity < 40:\n",
        "            self.similarity_30_40.append(cluster)\n",
        "        elif 40 <= similarity < 50:\n",
        "            self.similarity_40_50.append(cluster)\n",
        "        elif 50 <= similarity < 60:\n",
        "            self.similarity_50_60.append(cluster)\n",
        "        elif 60 <= similarity < 70:\n",
        "            self.similarity_60_70.append(cluster)\n",
        "        elif 70 <= similarity < 80:\n",
        "            self.similarity_70_80.append(cluster)\n",
        "        elif 80 <= similarity < 90:\n",
        "            self.similarity_80_90.append(cluster)\n",
        "        elif 90 <= similarity <= 100:\n",
        "            self.similarity_90_100.append(cluster)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueI9UNZpBbLZ"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import sys\n",
        "import time\n",
        "import shapely\n",
        "from collections import defaultdict\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from multiprocessing import Pool, cpu_count\n",
        "from tqdm import tqdm\n",
        "import multiprocessing\n",
        "#from utilities import CsvReader\n",
        "#from datamodel import RelatedGeometries\n",
        "\n",
        "class Similarity_Results:\n",
        "\n",
        "    def __init__(self, delimiter: str, sourceFilePath: str, targetFilePath: str, outputDirectoryPath: str):\n",
        "\n",
        "        # Load and process datasets using multiprocessing\n",
        "        with multiprocessing.Pool(processes=2) as pool:\n",
        "            results = pool.starmap(CsvReader.readAllEntities, [\n",
        "                (delimiter, sourceFilePath),\n",
        "                (delimiter, targetFilePath)\n",
        "            ])\n",
        "\n",
        "        # Store processed source and target data\n",
        "        self.sourceData, self.targetData = results\n",
        "\n",
        "        print('Source geometries:', len(self.sourceData))\n",
        "        print('Target geometries:', len(self.targetData))\n",
        "\n",
        "        self.relations = RelatedGeometries()\n",
        "        self.similarity_calculator = ShapeSimilarity()\n",
        "        self.spatialIndex = defaultdict(lambda: defaultdict(list))\n",
        "        self.verifiedClusters = set()\n",
        "        self.flag = [-1] * len(self.sourceData)\n",
        "        self.frequency = [-1] * len(self.sourceData)\n",
        "        self.output_dir = outputDirectoryPath\n",
        "\n",
        "    def applyProcessing(self) :\n",
        "      \"\"\"\n",
        "      Execute the complete algorithm pipeline:\n",
        "      1. Index the source geometries.\n",
        "      2. Verify all clusters and find their similarity index.\n",
        "      \"\"\"\n",
        "      time1 = int(time.time() * 1000)\n",
        "      self.setThetas()\n",
        "      self.indexSource()\n",
        "      time2 = int(time.time() * 1000)\n",
        "      self.verification()\n",
        "      time3 = int(time.time() * 1000)\n",
        "\n",
        "      print(\"Indexing Time\\t:\\t\" + str(time2 - time1))\n",
        "      print(\"Verification Time\\t:\\t\" + str(time3 - time2))\n",
        "      self.relations.print()\n",
        "\n",
        "    def indexSource(self) :\n",
        "      \"\"\"\n",
        "      Index source geometries into a spatial grid for fast candidate lookup.\n",
        "      Each geometry's bounding box is divided into grid cells.\n",
        "      \"\"\"\n",
        "      geometryId = 0\n",
        "      for sEntity in self.sourceData:\n",
        "        self.addToIndex(geometryId, sEntity.bounds)\n",
        "        geometryId += 1\n",
        "\n",
        "    def addToIndex(self, geometryId, envelope) :\n",
        "        \"\"\"\n",
        "        Adds a geometry to the spatial index.\n",
        "        \"\"\"\n",
        "        maxX = math.ceil(envelope[2] / self.thetaX)\n",
        "        maxY = math.ceil(envelope[3] / self.thetaY)\n",
        "        minX = math.floor(envelope[0] / self.thetaX)\n",
        "        minY = math.floor(envelope[1] / self.thetaY)\n",
        "        for latIndex in range(minX, maxX+1):\n",
        "          for longIndex in range(minY, maxY+1):\n",
        "              self.spatialIndex[latIndex][longIndex].append(geometryId)\n",
        "\n",
        "\n",
        "    def getCandidates(self, targetId):\n",
        "        candidates = set()\n",
        "\n",
        "        targetGeom = self.targetData[targetId]\n",
        "        envelope = targetGeom.envelope.bounds\n",
        "        maxX = math.ceil(envelope[2] / self.thetaX)\n",
        "        maxY = math.ceil(envelope[3] / self.thetaY)\n",
        "        minX = math.floor(envelope[0] / self.thetaX)\n",
        "        minY = math.floor(envelope[1] / self.thetaY)\n",
        "\n",
        "        for latIndex in range(minX, maxX+1):\n",
        "          for longIndex in range(minY,maxY+1):\n",
        "              for sourceId in self.spatialIndex[latIndex][longIndex]:\n",
        "                  if (self.flag[sourceId] != targetId): #!!!!!!THIS LINE WAS DEBUGGED\n",
        "                      self.flag[sourceId] = targetId\n",
        "                      self.frequency[sourceId] = 0\n",
        "                  self.frequency[sourceId] += 1\n",
        "                  candidates.add(sourceId)\n",
        "\n",
        "        return candidates\n",
        "\n",
        "\n",
        "    def setThetas(self):\n",
        "        \"\"\"\n",
        "        Compute average grid cell dimensions (thetaX, thetaY) based on source geometries.\n",
        "        This determines the size of each spatial grid cell.\n",
        "        \"\"\"\n",
        "        self.thetaX, self.thetaY = 0, 0\n",
        "        for sEntity in self.sourceData:\n",
        "            envelope = sEntity.envelope.bounds\n",
        "            self.thetaX += envelope[2] - envelope[0]\n",
        "            self.thetaY += envelope[3] - envelope[1]\n",
        "\n",
        "        self.thetaX /= len(self.sourceData)\n",
        "        self.thetaY /= len(self.sourceData)\n",
        "        print(\"Dimensions of Equigrid\", self.thetaX,\"and\", self.thetaY)\n",
        "\n",
        "\n",
        "    def verification(self):\n",
        "\n",
        "        \"\"\"\n",
        "        Performs cluster verification and calculate similarity metrics:\n",
        "        - Computes average similarity for each target geometry's candidate matches (clusters).\n",
        "        - Identifies target geometries with low similarity values (<=10).\n",
        "        - Saves results and low-similarity target data to CSV files.\n",
        "        \"\"\"\n",
        "\n",
        "        # Create the directory if it doesn't exist\n",
        "        #os.makedirs(self.output_dir, exist_ok=True)\n",
        "\n",
        "        # Initialize counters and data structures for verification\n",
        "        totalDecisions, truePositiveDecisions, counter = len(self.verifiedClusters), 0, 0\n",
        "        all_similarities = []  # List to store all average similarities\n",
        "        similarity_data = []   # List to store target ID and its respective similarity\n",
        "        zero_to_ten_similarity = []  # List to store target IDs with average similarity <= 10\n",
        "\n",
        "        # Wrap the loop with tqdm for true positive calculations\n",
        "        for targetId in tqdm(range(len(self.targetData)), desc=\"Calculating Recall\", unit=\"prediction\"):\n",
        "            candidateMatches = self.getCandidates(targetId)\n",
        "            if len(candidateMatches) > 1:\n",
        "              # Map candidateMatches indexes to their corresponding polygons\n",
        "              candidatePolygons = [self.sourceData[idx] for idx in candidateMatches]\n",
        "\n",
        "              average_similarity = self.similarity_calculator.calculate_similarity_all_pairs(candidatePolygons)\n",
        "\n",
        "              # Collect target IDs with average similarity <= 10\n",
        "              if average_similarity <= 10:\n",
        "                  zero_to_ten_similarity.append((targetId, average_similarity))\n",
        "\n",
        "              # Append the average similarity to the list\n",
        "              all_similarities.append(average_similarity)\n",
        "\n",
        "              # Store targetId and its average similarity\n",
        "              similarity_data.append((targetId, average_similarity))\n",
        "\n",
        "              if self.relations.verifyRelations(counter, average_similarity):\n",
        "                  #print(\"True Positive\")\n",
        "                  truePositiveDecisions += 1\n",
        "            counter += 1\n",
        "\n",
        "        # Calculate the overall average similarity\n",
        "        overall_average_similarity = sum(all_similarities) / len(all_similarities) if all_similarities else 0\n",
        "        print(f\"Overall Average Similarity: {overall_average_similarity}\")\n",
        "        print(\"True Positive Decisions\\t:\\t\" + str(truePositiveDecisions))\n",
        "\n",
        "        # Paths for the CSV files in Google Drive\n",
        "        csv_file = os.path.join(self.output_dir, \"similarity_results.csv\")\n",
        "        zero_to_ten_csv_file = os.path.join(self.output_dir, \"low_similarity_results.csv\")\n",
        "\n",
        "        # Write the target IDs and average similarities to a CSV file\n",
        "        with open(csv_file, mode='w', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            # Write header row\n",
        "            writer.writerow([\"Cluster ID\", \"Average Similarity\"])\n",
        "            # Write data rows\n",
        "            writer.writerows(similarity_data)\n",
        "\n",
        "        print(f\"Similarity results saved to {csv_file}\")\n",
        "\n",
        "        # Write the target IDs with average similarity <= 10 to another CSV file\n",
        "        with open(zero_to_ten_csv_file, mode='w', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            # Write header row\n",
        "            writer.writerow([\"Cluster ID\", \"Average Similarity <= 10\"])\n",
        "            # Write data rows\n",
        "            writer.writerows(zero_to_ten_similarity)\n",
        "\n",
        "        print(f\"Low similarity results saved to {zero_to_ten_csv_file}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwW5HIXQe2q6",
        "outputId": "10466714-2f15-441d-e1be-6559eb98763f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total entities: 583833, Geometry collections: 0\n",
            "Total entities: 229276, Geometry collections: 0\n",
            "Source geometries: 229276\n",
            "Target geometries: 583833\n",
            "Dimensions of Equigrid 0.009110405127444583 and 0.0068148931157206456\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Calculating Recall: 100%|██████████| 583833/583833 [1:21:13<00:00, 119.79prediction/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall Average Similarity: 56.50621492994735\n",
            "True Positive Decisions\t:\t0\n",
            "Similarity results saved to ../content/drive/MyDrive/hpml_final_project/D1/similarity_results.csv\n",
            "Low similarity results saved to ../content/drive/MyDrive/hpml_final_project/D1/low_similarity_results.csv\n",
            "Indexing Time\t:\t11919\n",
            "Verification Time\t:\t4874137\n",
            "Clusters in 0-10% similarity range:\t 0\n",
            "Clusters in 10-20% similarity range:\t 0\n",
            "Clusters in 20-30% similarity range:\t 68\n",
            "Clusters in 30-40% similarity range:\t 10864\n",
            "Clusters in 40-50% similarity range:\t 64553\n",
            "Clusters in 50-60% similarity range:\t 121251\n",
            "Clusters in 60-70% similarity range:\t 68206\n",
            "Clusters in 70-80% similarity range:\t 27246\n",
            "Clusters in 80-90% similarity range:\t 3215\n",
            "Clusters in 90-100% similarity range:\t 65\n",
            "Verified Clusters 295481\n"
          ]
        }
      ],
      "source": [
        "main_dir = '../content/drive/MyDrive/hpml_final_project/D1/'\n",
        "\n",
        "sg = Similarity_Results(delimiter='\\t',  sourceFilePath=main_dir + 'SourceDataset.csv', targetFilePath=main_dir + 'TargetDataset.csv', outputDirectoryPath = main_dir)\n",
        "sg.applyProcessing()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jU57pNUC5f7",
        "outputId": "22d8071e-e5db-4c33-ef7a-421ed6224183"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total entities: 210483, Geometry collections: 0\n",
            "Total entities: 2898899, Geometry collections: 0\n",
            "Source geometries: 210483\n",
            "Target geometries: 2898899\n",
            "Dimensions of Equigrid 0.02034925282944467 and 0.01278916771425737\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Calculating Recall: 100%|██████████| 2898899/2898899 [3:27:57<00:00, 232.34prediction/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall Average Similarity: 60.030136776775194\n",
            "True Positive Decisions\t:\t0\n",
            "Similarity results saved to ../content/drive/MyDrive/hpml_final_project/D2/similarity_results.csv\n",
            "Low similarity results saved to ../content/drive/MyDrive/hpml_final_project/D2/low_similarity_results.csv\n",
            "Indexing Time\t:\t8905\n",
            "Verification Time\t:\t12478341\n",
            "Clusters in 0-10% similarity range:\t 0\n",
            "Clusters in 10-20% similarity range:\t 0\n",
            "Clusters in 20-30% similarity range:\t 0\n",
            "Clusters in 30-40% similarity range:\t 3299\n",
            "Clusters in 40-50% similarity range:\t 49966\n",
            "Clusters in 50-60% similarity range:\t 289280\n",
            "Clusters in 60-70% similarity range:\t 254385\n",
            "Clusters in 70-80% similarity range:\t 45820\n",
            "Clusters in 80-90% similarity range:\t 9243\n",
            "Clusters in 90-100% similarity range:\t 2181\n",
            "Verified Clusters 654196\n"
          ]
        }
      ],
      "source": [
        "main_dir = '../content/drive/MyDrive/hpml_final_project/D2/'\n",
        "\n",
        "sg = Similarity_Results(delimiter='\\t',  sourceFilePath=main_dir + 'SourceDataset.csv', targetFilePath=main_dir + 'TargetDataset.csv', outputDirectoryPath = main_dir)\n",
        "sg.applyProcessing()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzG0Zoah0s0v",
        "outputId": "567bfb86-8375-4c9d-db5b-ead828efc01b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Source geometries 200294\n",
            "Target geometries 7392699\n",
            "Source geometries: 200294\n",
            "Target geometries: 7392699\n",
            "Dimensions of Equigrid 0.0224352825786094 and 0.014045209125086408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating Recall: 100%|██████████| 7392699/7392699 [21:42:24<00:00, 94.60prediction/s]  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Average Similarity: 60.56998794994542\n",
            "True Positive Decisions\t:\t1324980\n",
            "Similarity results saved to ../content/drive/MyDrive/hpml_final_project/D3/similarity_results.csv\n",
            "Low similarity results saved to ../content/drive/MyDrive/hpml_final_project/D3/low_similarity_results.csv\n",
            "Indexing Time\t:\t9004\n",
            "Verification Time\t:\t78147255\n",
            "Clusters in 0-10% similarity range:\t 0\n",
            "Clusters in 10-20% similarity range:\t 0\n",
            "Clusters in 20-30% similarity range:\t 0\n",
            "Clusters in 30-40% similarity range:\t 4143\n",
            "Clusters in 40-50% similarity range:\t 93512\n",
            "Clusters in 50-60% similarity range:\t 501648\n",
            "Clusters in 60-70% similarity range:\t 605463\n",
            "Clusters in 70-80% similarity range:\t 103164\n",
            "Clusters in 80-90% similarity range:\t 13195\n",
            "Clusters in 90-100% similarity range:\t 3582\n",
            "Verified Clusters 1324980\n"
          ]
        }
      ],
      "source": [
        "main_dir = '../content/drive/MyDrive/hpml_final_project/D3/'\n",
        "\n",
        "sg = Similarity_Results(delimiter='\\t',  sourceFilePath=main_dir + 'SourceDataset.csv', targetFilePath=main_dir + 'TargetDataset.csv', outputDirectoryPath = main_dir)\n",
        "sg.applyProcessing()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}